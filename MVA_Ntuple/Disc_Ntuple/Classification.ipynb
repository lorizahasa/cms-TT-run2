{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful when the notebook is running in tmux\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(hostname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputFileS = ROOT.TFile(\"sig_1000.root\")\n",
    "dirNtuple = \"root://cmseos.fnal.gov//store/user/rverma/Output/cms-TT-run2/Ntuple_Skim/\"\n",
    "dirFile = \"2016/Semilep/JetBase/\"\n",
    "sigFile = \"Semilep_JetBase__TstarTstarToTgammaTgluon_M800_2016_Ntuple.root\"\n",
    "inputFileS = ROOT.TFile.Open(\"%s/%s/%s\"%(dirNtuple, dirFile, sigFile))\n",
    "sig = inputFileS.Get(\"AnalysisTree\")\n",
    "\n",
    "bkg = ROOT.TChain(\"AnalysisTree\")\n",
    "bkgList = [\"TTGamma_SingleLept\", \n",
    "           \"TTGamma_Dilepton\", \n",
    "           \"TTGamma_Hadronic\", \n",
    "           \"TTGamma_SingleLept_Pt100\", \n",
    "           \"TTGamma_Dilepton_Pt100\", \n",
    "           \"TTGamma_Hadronic_Pt100\",\n",
    "           \"TTGamma_SingleLept_Pt200\", \n",
    "           \"TTGamma_Dilepton_Pt200\",\n",
    "           \"TTGamma_Hadronic_Pt200\"\n",
    "          ]\n",
    "for b in bkgList:\n",
    "    fPath = \"%s/%s/Semilep_JetBase__%s_2016_Ntuple.root\"%(dirNtuple, dirFile, b)\n",
    "    bkg.Add(fPath)\n",
    "print(bkg.GetEntries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ROOT.TMVA.DataLoader(\"dataset\")\n",
    "sigWeight = 1.0\n",
    "bkgWeight = 1.0\n",
    "loader.AddSignalTree(sig, sigWeight)\n",
    "loader.AddBackgroundTree(bkg, bkgWeight)\n",
    "\n",
    "loader.AddVariable(\"Reco_ht\" ,'F')\n",
    "loader.AddVariable(\"Reco_st\",'F')\n",
    "loader.AddVariable(\"Photon_et\",'F')\n",
    "loader.AddVariable(\"Reco_mass_T\" ,'F')\n",
    "\n",
    "loader.SetSignalWeightExpression(\"Weight_lumi\")\n",
    "loader.SetBackgroundWeightExpression(\"Weight_lumi\")\n",
    "\n",
    "#cut1 = ROOT.TCut(\"pt_j1 > 50\")\n",
    "cut1 = ROOT.TCut(\"Event_pass_presel_mu &&((Jet_size>=5 && FatJet_size==0) || (Jet_size>=2 && FatJet_size==1))  && Jet_b_size >=1 && Photon_size==1 && Photon_et[0] > 100\")\n",
    "#cut1 = ROOT.TCut(\"((Jet_size>=5 && FatJet_size==0) || (Jet_size>=2 && FatJet_size==1)) && Jet_b_size >=1 && Photon_size==1 && Photon_et > 100\")\n",
    "#loader.PrepareTrainingAndTestTree(cut1,'SplitMode=Random:NormMode=NumEvents:!V')\n",
    "\n",
    "loader.PrepareTrainingAndTestTree(cut1,\"SplitMode=Random:!V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ROOT.TMVA.Tools.Instance()\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize();\n",
    "\n",
    "outputFile = ROOT.TFile.Open(\"mT800_Test.root\", \"RECREATE\")\n",
    "\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_TT_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )\n",
    "factory.BookMethod(loader,TMVA.Types.kBDT, \"BDTG_mT800\",\n",
    "                   \"!V:NTrees=200:MinNodeSize=1%:MaxDepth=4:BoostType=Grad:Shrinkage=0.02:UseBaggedBoost:\"\n",
    "                   \"BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=-1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.TrainAllMethods();\n",
    "factory.TestAllMethods();\n",
    "factory.EvaluateAllMethods();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "c1 = factory.GetROCCurve(loader);\n",
    "c1.Draw();\n",
    "outputFile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "#Read output directly from classification\n",
    "#--------------------------------------------\n",
    "#inDir = \"%s/%s/%s/%s/Merged\"%(condorHistDir, year, decayMode, channel)\n",
    "#inFile = TFile.Open(\"%s/AllInc.root\"%inDir, \"read\")\n",
    "inFile = ROOT.TFile.Open(\"mT800_Test.root\", \"read\")\n",
    "outputFile = ROOT.TFile(\"Disc_Ntuple.root\",\"RECREATE\")\n",
    "\n",
    "CR = \"ttyg_Enriched_SR\"\n",
    "def getHistDir(sample, sysType, CR):\n",
    "    histDir = \"%s/%s/%s\"%(sample, CR, sysType)\n",
    "    return histDir\n",
    "\n",
    "def writeHist(hist, procDir, outputFile):\n",
    "    outHistDir = getHistDir(procDir, \"Base\", CR)\n",
    "    if not outputFile.GetDirectory(outHistDir):\n",
    "        outputFile.mkdir(outHistDir)\n",
    "    outputFile.cd(outHistDir)\n",
    "    ROOT.gDirectory.Delete(\"%s;*\"%(hist.GetName()))\n",
    "    print \"%20s, %10s, %10s\"%(hist.GetName(), procDir, round(hist.Integral()))\n",
    "    #hNew = hist.Rebin(len(newBins)-1, histNewName, newBins) \n",
    "    #hNew.Write()\n",
    "    hist.Write()\n",
    "\n",
    "def getHist(inHistName, procDir, sysType):\n",
    "    print(inHistName, procDir)\n",
    "    hist = inFile.Get(\"dataset/InputVariables_Id/%s__%s_Id\"%(inHistName, procDir)).Clone(inHistName)\n",
    "    return hist, procDir, sysType\n",
    "\n",
    "def getDisc(inHistName, procDir, sysType, s):\n",
    "    hist = inFile.Get(\"dataset/Method_BDTG_mT800/BDTG_mT800/MVA_BDTG_mT800_%s\"%(s)).Clone(inHistName)\n",
    "    return hist, procDir, sysType\n",
    "\n",
    "procList = [\"Signal\", \"Background\"]\n",
    "histList = [\"Reco_st\", \"Reco_ht\", \"Photon_et\", \"Reco_mass_T\"]\n",
    "\n",
    "writeList = []\n",
    "for p in procList:\n",
    "    for h in histList:\n",
    "        writeList.append(getHist(h, p, \"Base\"))\n",
    "\n",
    "writeList.append(getDisc(\"BDT_Disc\", \"Signal\", \"Base\", \"S\"))\n",
    "writeList.append(getDisc(\"BDT_Disc\", \"Background\", \"Base\", \"B\"))\n",
    "\n",
    "for write in writeList:\n",
    "    writeHist(write[0], write[1], outputFile)\n",
    "    if \"Back\" in write[1]:\n",
    "        writeHist(write[0], \"data_obs\", outputFile)\n",
    "\n",
    "outputFile.ls()\n",
    "outputFile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN model\n",
    "#inputLayoutString = \"InputLayout=1|1|21\"; \n",
    "#batchLayoutString= \"BatchLayout=1|256|21\";\n",
    "#layoutString = (\"Layout=DENSE|100|RELU,DENSE|100|RELU,DENSE|64|RELU,DENSE|64|RELU,DENSE|1|LINEAR\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training strategies \n",
    "## one can catenate several training strategies\n",
    "\n",
    "#training1  = \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,\"\n",
    "#training1 += \"DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=256,TestRepetitions=1\"\n",
    " \n",
    "# we add regularization in the second phase\n",
    "#training2  = \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=L2,WeightDecay=1e-4,\"\n",
    "#training2 += \"DropConfig=0.0+0.0+0.0+0,MaxEpochs=20,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1\"\n",
    "     \n",
    "            \n",
    "\n",
    "#trainingStrategyString = \"TrainingStrategy=\" + training1 ## + training2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Options.                                                                                                                                                                \n",
    "#dnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G,N:WeightInitialization=XAVIER::Architecture=CPU\"\n",
    "\n",
    "#dnnOptions +=  \":\" + inputLayoutString\n",
    "#dnnOptions +=  \":\" + batchLayoutString\n",
    "#dnnOptions +=  \":\" + layoutString\n",
    "#dnnOptions +=  \":\" + trainingStrategyString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now book the method\n",
    "              \n",
    "#factory.BookMethod(loader, ROOT.TMVA.Types.kDL, \"DL_CPU\", dnnOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factory.BookMethod(loader, ROOT.TMVA.Types.kPyGTB, \"PyGTB\",\"H:!V:VarTransform=G:NEstimators=1000:LearningRate=0.01:\"\n",
    "#                                                  \"MaxDepth=4\")\n",
    "\n",
    "#factory.BookMethod(loader, ROOT.TMVA.Types.kPyRandomForest, \"PyRandomForest\",\"!V:VarTransform=G:NEstimators=400:\"\n",
    "#                          \"Criterion=gini:MaxFeatures=auto:MaxDepth=6:MinSamplesLeaf=3:MinWeightFractionLeaf=0:\"\n",
    "#                           \"Bootstrap=kTRUE\" )\n",
    "      \n",
    "#factory.BookMethod(loader, ROOT.TMVA.Types.kPyAdaBoost, \"PyAdaBoost\",\"!V:VarTransform=G:NEstimators=400\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
